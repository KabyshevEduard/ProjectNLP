{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebf1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import natasha\n",
    "from navec import Navec\n",
    "from slovnet.model.emb import NavecEmbedding\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71197ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Эдуард\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Эдуард\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec = Navec.load(path)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f8ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path, sep, encoding, subset='train'):\n",
    "        self.subset = subset\n",
    "        self.df = pd.read_csv(path, sep=sep, encoding=encoding)\n",
    "        self.length_of_vec = 0\n",
    "        for i in range(len(self.df)):\n",
    "            if len(self.df['Описание анкеты'].values[i].split(' ')) > self.length_of_vec:\n",
    "                self.length_of_vec = len(self.df['Описание анкеты'].values[i].split(' '))\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = model_selection.train_test_split(self.df['Описание анкеты'], self.df[' Рекомендовать'], test_size=0.33, random_state=42)\n",
    "    \n",
    "    def vectorize(self, disc):\n",
    "        tokens = nltk.word_tokenize(disc, language='russian')\n",
    "        tokens_without_punct = [str(token) for token in tokens if token not in string.punctuation]\n",
    "        without_stop_words = [str(token) for token in tokens_without_punct if token not in nltk.corpus.stopwords.words('russian')]\n",
    "        #snowball = nltk.stem.snowball.SnowballStemmer('russian')\n",
    "        #stemmed_tokens = [str(snowball.stem(i)) for i in without_stop_words] леммизация\n",
    "        ids = []\n",
    "        for j in without_stop_words:\n",
    "            if j.lower() in navec:\n",
    "                ids.append(navec.vocab[j.lower()])\n",
    "            else:\n",
    "                ids.append(navec.vocab['<unk>'])\n",
    "        if len(ids) < self.length_of_vec:\n",
    "            addition = [0 for i in range(self.length_of_vec - len(ids))]\n",
    "            ids += addition\n",
    "        return torch.tensor(ids)\n",
    "                \n",
    "    def __len__(self):\n",
    "        if self.subset == 'train':\n",
    "            return len(self.x_train)\n",
    "        else:\n",
    "            return len(self.x_test)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.subset == 'train':\n",
    "            disc = self.x_train.values[index]\n",
    "            recomend = self.y_train.values[index]\n",
    "        else:\n",
    "            disc = self.x_test.values[index]\n",
    "            recomend = self.y_test.values[index]\n",
    "        if type(disc) is str:\n",
    "            return self.vectorize(disc), torch.tensor(recomend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71903f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = 'C:/Users/Эдуард/Desktop/проект/data.txt'\n",
    "sep = ';'\n",
    "encoding = 'cp1251'\n",
    "data = DataPreprocessing(path_df, sep, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b79610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(data)\n",
    "learning_rate = 0.001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98ef4b",
   "metadata": {},
   "source": [
    "Input matrix 44x300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00e689e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    embedding = NavecEmbedding(navec)\n",
    "    x, _ = data[0]\n",
    "    dim = len(x)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(self.dim, self.dim, 10),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Conv1d(self.dim, self.dim, 50),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Conv1d(self.dim, 12, 20),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(348, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, 20),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(20, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded_x = self.embedding(x)\n",
    "        y = self.sequential(embedded_x)\n",
    "        return y\n",
    "    \n",
    "    def trainn(self, data, batch_size, epochs):\n",
    "        dl = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), weight_decay=0.009)\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch, (X, Y) in enumerate(dl):\n",
    "                optimizer.zero_grad()\n",
    "                #pred = torch.tensor([model(X[i]) for i in range(len(X))], requires_grad=True)\n",
    "                #target = Y.to(torch.float32)\n",
    "                pred = self(X)\n",
    "                target = torch.reshape(Y, (-1, 1)).float()\n",
    "                loss = loss_fn(pred, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if batch % 1 == 0:\n",
    "                    loss, current = loss.item(), (batch + 1)*len(X)\n",
    "                    print(f'{epoch+1}/{epochs}')\n",
    "                    print(f'batch: {batch}; loss = {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cb2aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572edb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100\n",
      "batch: 0; loss = 0.7507927417755127\n",
      "2/100\n",
      "batch: 0; loss = 0.7105888724327087\n",
      "3/100\n",
      "batch: 0; loss = 0.6495482921600342\n",
      "4/100\n",
      "batch: 0; loss = 0.5817843675613403\n",
      "5/100\n",
      "batch: 0; loss = 0.5726590752601624\n",
      "6/100\n",
      "batch: 0; loss = 0.5982565879821777\n",
      "7/100\n",
      "batch: 0; loss = 0.5709444880485535\n",
      "8/100\n",
      "batch: 0; loss = 0.5598000884056091\n",
      "9/100\n",
      "batch: 0; loss = 0.5697249174118042\n",
      "10/100\n",
      "batch: 0; loss = 0.5742855072021484\n",
      "11/100\n",
      "batch: 0; loss = 0.5689115524291992\n",
      "12/100\n",
      "batch: 0; loss = 0.5608711242675781\n",
      "13/100\n",
      "batch: 0; loss = 0.5569228529930115\n",
      "14/100\n",
      "batch: 0; loss = 0.5585339665412903\n",
      "15/100\n",
      "batch: 0; loss = 0.5607529878616333\n",
      "16/100\n",
      "batch: 0; loss = 0.5592071413993835\n",
      "17/100\n",
      "batch: 0; loss = 0.5558499693870544\n",
      "18/100\n",
      "batch: 0; loss = 0.5546475648880005\n",
      "19/100\n",
      "batch: 0; loss = 0.555702269077301\n",
      "20/100\n",
      "batch: 0; loss = 0.5564998984336853\n",
      "21/100\n",
      "batch: 0; loss = 0.5558892488479614\n",
      "22/100\n",
      "batch: 0; loss = 0.5541115403175354\n",
      "23/100\n",
      "batch: 0; loss = 0.5523744225502014\n",
      "24/100\n",
      "batch: 0; loss = 0.5516955852508545\n",
      "25/100\n",
      "batch: 0; loss = 0.5517522096633911\n",
      "26/100\n",
      "batch: 0; loss = 0.5512230396270752\n",
      "27/100\n",
      "batch: 0; loss = 0.5497493743896484\n",
      "28/100\n",
      "batch: 0; loss = 0.548439085483551\n",
      "29/100\n",
      "batch: 0; loss = 0.54796302318573\n",
      "30/100\n",
      "batch: 0; loss = 0.5476077795028687\n",
      "31/100\n",
      "batch: 0; loss = 0.5463577508926392\n",
      "32/100\n",
      "batch: 0; loss = 0.5443379878997803\n",
      "33/100\n",
      "batch: 0; loss = 0.5424692630767822\n",
      "34/100\n",
      "batch: 0; loss = 0.5411262512207031\n",
      "35/100\n",
      "batch: 0; loss = 0.5391766428947449\n",
      "36/100\n",
      "batch: 0; loss = 0.5366649031639099\n",
      "37/100\n",
      "batch: 0; loss = 0.5348057746887207\n",
      "38/100\n",
      "batch: 0; loss = 0.5323004126548767\n",
      "39/100\n",
      "batch: 0; loss = 0.5291239023208618\n",
      "40/100\n",
      "batch: 0; loss = 0.5262577533721924\n",
      "41/100\n",
      "batch: 0; loss = 0.5220712423324585\n",
      "42/100\n",
      "batch: 0; loss = 0.5183389186859131\n",
      "43/100\n",
      "batch: 0; loss = 0.5130442976951599\n",
      "44/100\n",
      "batch: 0; loss = 0.5074319243431091\n",
      "45/100\n",
      "batch: 0; loss = 0.5013388395309448\n",
      "46/100\n",
      "batch: 0; loss = 0.4941127896308899\n",
      "47/100\n",
      "batch: 0; loss = 0.4865570664405823\n",
      "48/100\n",
      "batch: 0; loss = 0.4809359610080719\n",
      "49/100\n",
      "batch: 0; loss = 0.4737664759159088\n",
      "50/100\n",
      "batch: 0; loss = 0.46741408109664917\n",
      "51/100\n",
      "batch: 0; loss = 0.451235294342041\n",
      "52/100\n",
      "batch: 0; loss = 0.4433460235595703\n",
      "53/100\n",
      "batch: 0; loss = 0.44011521339416504\n",
      "54/100\n",
      "batch: 0; loss = 0.46543726325035095\n",
      "55/100\n",
      "batch: 0; loss = 0.46814852952957153\n",
      "56/100\n",
      "batch: 0; loss = 0.4204256534576416\n",
      "57/100\n",
      "batch: 0; loss = 0.4296802878379822\n",
      "58/100\n",
      "batch: 0; loss = 0.4166288375854492\n",
      "59/100\n",
      "batch: 0; loss = 0.4001270532608032\n",
      "60/100\n",
      "batch: 0; loss = 0.41557881236076355\n",
      "61/100\n",
      "batch: 0; loss = 0.38599205017089844\n",
      "62/100\n",
      "batch: 0; loss = 0.38751280307769775\n",
      "63/100\n",
      "batch: 0; loss = 0.41518208384513855\n",
      "64/100\n",
      "batch: 0; loss = 0.36322304606437683\n",
      "65/100\n",
      "batch: 0; loss = 0.36553123593330383\n",
      "66/100\n",
      "batch: 0; loss = 0.4230712950229645\n",
      "67/100\n",
      "batch: 0; loss = 0.3481779992580414\n",
      "68/100\n",
      "batch: 0; loss = 0.3500436544418335\n",
      "69/100\n",
      "batch: 0; loss = 0.39106929302215576\n",
      "70/100\n",
      "batch: 0; loss = 0.3257441520690918\n",
      "71/100\n",
      "batch: 0; loss = 0.37545502185821533\n",
      "72/100\n",
      "batch: 0; loss = 0.3980410695075989\n",
      "73/100\n",
      "batch: 0; loss = 0.32777997851371765\n",
      "74/100\n",
      "batch: 0; loss = 0.43399420380592346\n",
      "75/100\n",
      "batch: 0; loss = 0.30878469347953796\n",
      "76/100\n",
      "batch: 0; loss = 0.4064122140407562\n",
      "77/100\n",
      "batch: 0; loss = 0.30606329441070557\n",
      "78/100\n",
      "batch: 0; loss = 0.39092323184013367\n",
      "79/100\n",
      "batch: 0; loss = 0.3029539883136749\n",
      "80/100\n",
      "batch: 0; loss = 0.3768155574798584\n",
      "81/100\n",
      "batch: 0; loss = 0.2941388189792633\n",
      "82/100\n",
      "batch: 0; loss = 0.3474324345588684\n",
      "83/100\n",
      "batch: 0; loss = 0.2816295623779297\n",
      "84/100\n",
      "batch: 0; loss = 0.3217621147632599\n",
      "85/100\n",
      "batch: 0; loss = 0.27238795161247253\n",
      "86/100\n",
      "batch: 0; loss = 0.26627853512763977\n",
      "87/100\n",
      "batch: 0; loss = 0.2954641878604889\n",
      "88/100\n",
      "batch: 0; loss = 0.2352028489112854\n",
      "89/100\n",
      "batch: 0; loss = 0.25887584686279297\n",
      "90/100\n",
      "batch: 0; loss = 0.36327123641967773\n",
      "91/100\n",
      "batch: 0; loss = 0.2125597596168518\n",
      "92/100\n",
      "batch: 0; loss = 0.3455759584903717\n",
      "93/100\n",
      "batch: 0; loss = 0.4836145043373108\n",
      "94/100\n",
      "batch: 0; loss = 0.4153165817260742\n",
      "95/100\n",
      "batch: 0; loss = 0.24342797696590424\n",
      "96/100\n",
      "batch: 0; loss = 0.35763019323349\n",
      "97/100\n",
      "batch: 0; loss = 0.3976380228996277\n",
      "98/100\n",
      "batch: 0; loss = 0.4172949492931366\n",
      "99/100\n",
      "batch: 0; loss = 0.2691081166267395\n",
      "100/100\n",
      "batch: 0; loss = 0.3232533633708954\n"
     ]
    }
   ],
   "source": [
    "model.trainn(data, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f481543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data, metric=True, i=0,):\n",
    "    if metric:\n",
    "        dl = torch.utils.data.DataLoader(data, batch_size=len(data))\n",
    "        for X, Y in dl:\n",
    "            Y_pred = []\n",
    "            arr = torch.reshape(model(X), (len(data), )).detach().numpy()\n",
    "            for i in arr:\n",
    "                if i >= 0.5:\n",
    "                    Y_pred.append(1)\n",
    "                elif i < 0.5:\n",
    "                    Y_pred.append(0) \n",
    "            rec = metrics.recall_score(Y.detach().numpy(), np.array(Y_pred))\n",
    "            prec = metrics.precision_score(Y.detach().numpy(), np.array(Y_pred))\n",
    "        print(f'recall = {rec}; precision = {prec}')\n",
    "    else:\n",
    "        x, y = data[i]\n",
    "        x = torch.reshape(x, (1, 44))\n",
    "        print(f'predicted = {model(x)}: true = {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d9edb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "200a2e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall = 0.875; precision = 0.7567567567567568\n"
     ]
    }
   ],
   "source": [
    "predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d16757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = DataPreprocessing(path_df, sep, encoding, subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1f52ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall = 0.25; precision = 0.25\n"
     ]
    }
   ],
   "source": [
    "predict(model, data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
